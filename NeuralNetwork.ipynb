{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSJvHJ7VnEl7uOUG6nDduP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiragraokv/MachineLearning/blob/main/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BH6pYeoC9xl0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Layers_hidden:\n",
        "    def __init__(self,Weights_no,neuron_no):\n",
        "        self.weights = np.random.randn(neuron_no, Weights_no)\n",
        "        self.bias = np.random.randn(neuron_no)\n",
        "\n",
        "    def ReLU(self,x):\n",
        "        return np.maximum(x,0)\n",
        "\n",
        "    def Process(self,input):\n",
        "        self.input = input\n",
        "        self.y = np.dot(self.weights,self.input) + self.bias  #gives an array of output with no of elements  = no of neuron\n",
        "        self.z = self.ReLU(self.y) #activation function based of the layer being used\n",
        "        self.output_layer_hidden = self.z\n",
        "        return self.z\n",
        "\n",
        "    def Backward_propogation_hidden(self,dvalue,learning_rate):\n",
        "        self.dw = np.dot(dvalue,self.input)\n",
        "        self.dx = np.dot(dvalue,self.weights)\n",
        "        self.db = dvalue\n",
        "        self.update_parameters(learning_rate)\n",
        "        return np.average(self.dx)\n",
        "\n",
        "    def update_parameters(self,learning_rate):\n",
        "        self.weights = self.weights +learning_rate*self.dw\n",
        "        self.bias = self.bias + learning_rate*self.db\n",
        "\n",
        "class Layer_output:\n",
        "    def __init__(self,Weights_no,neuron_no):\n",
        "        self.weights = np.random.randn(neuron_no, Weights_no)\n",
        "        self.bias = np.random.randn(neuron_no)\n",
        "\n",
        "    def Softmax(self,x):\n",
        "        x = x-np.max(x)\n",
        "        return ((np.exp(x))/np.sum(np.exp(x)))\n",
        "\n",
        "    def Process(self,input):\n",
        "        self.input = input\n",
        "        self.y = np.dot(self.weights,self.input) + self.bias  #gives an array of output with no of elements  = no of neuron this is for output layer\n",
        "        self.z = self.Softmax(self.y)\n",
        "        self.output_layer = self.z\n",
        "        return self.z\n",
        "\n",
        "    def Cross_entropy_loss(self,Y_actual):\n",
        "        return (-np.sum(Y_actual*(np.log(self.output_layer + 1e-8))))\n",
        "\n",
        "    def Backward_propogation_output(self,yactual,learning_rate):\n",
        "\n",
        "        self.dw = np.dot((yactual - self.output_layer),self.input)\n",
        "        self.dx = np.dot((yactual - self.output_layer),self.weights)\n",
        "        self.db = (yactual - self.output_layer)\n",
        "        self.update_parameters(learning_rate)\n",
        "        return np.average(self.dx)\n",
        "\n",
        "    def update_parameters(self,learning_rate):\n",
        "        self.weights = self.weights + learning_rate*self.dw\n",
        "        self.bias = self.bias + learning_rate*self.db\n"
      ],
      "metadata": {
        "id": "ssBApCw59_6J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train_Test_Neural_network:\n",
        "    def __init__(self,layer_info,X_train,Y_train,X_test,Y_test):\n",
        "        self.no_Layers = len(layer_info)-1\n",
        "        self.Layer_size = layer_info\n",
        "        self.Layer = []\n",
        "        self.loss_in_one_itiration = 0\n",
        "        self.Loss = []\n",
        "        self.X_train = X_train\n",
        "        self.Y_train= Y_train\n",
        "        self.X_train_scrap = X_train[0, : ]\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.dw = 0\n",
        "        self.dx =0\n",
        "        self.db = 0\n",
        "        for i in range(self.no_Layers):\n",
        "            self.Layer.append(Layers_hidden(len(self.X_train_scrap),self.Layer_size[i])) #making of object list and inisializing parameters.\n",
        "            self.X_train_scrap = self.Layer[i].Process(self.X_train_scrap)\n",
        "        self.Layer_last = Layer_output(len(self.X_train_scrap),self.Layer_size[i+1])\n",
        "        print(\"command out of initialization\\n\")\n",
        "\n",
        "    def execute_through_layers(self,X):\n",
        "        for i in range(self.no_Layers):\n",
        "            X = self.Layer[i].Process(X)\n",
        "        self.X_last = self.Layer_last.Process(X)\n",
        "\n",
        "    def gradient_descent(self,Y_test):\n",
        "        self.Y_test_1 = Y_test\n",
        "        for i in range(self.no_Layers):\n",
        "            self.dx_last_layer = self.Layer_last.Backward_propogation_output(self.Y_test_1,self.learning_rate)\n",
        "            for j in range(self.no_Layers):\n",
        "                self.dx = self.Layer[i].Backward_propogation_hidden(self.dx_last_layer,self.learning_rate)\n",
        "\n",
        "    def Train_layers(self,itirations,learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "        for i in range(itirations):\n",
        "            for j in range(self.X_train.shape[0]):\n",
        "                self.execute_through_layers(self.X_train[j]) # this function is called to execute through layers each time\n",
        "                self.loss_in_one_itiration = self.loss_in_one_itiration + (self.Layer_last.Cross_entropy_loss(self.Y_train[j]))  # to save the Cross entropy loss in each itiration\n",
        "                self.gradient_descent(self.Y_test[j])\n",
        "            self.loss_in_one_itiration = self.loss_in_one_itiration/self.X_train.shape[0]\n",
        "            self.Loss.append(self.loss_in_one_itiration)\n",
        "            self.loss_in_one_itiration = 0\n"
      ],
      "metadata": {
        "id": "PtbOvbSH-IPF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class One_hot_encodeing():\n",
        "    def __init__(self,data,categories):\n",
        "        self.categories = categories\n",
        "        self.data = data\n",
        "        self.Y_one_hot = np.zeros(shape=(data.shape[0],self.categories.shape[0]))\n",
        "\n",
        "    def encode(self):\n",
        "        for index,cat in enumerate(self.data[:,-1]):\n",
        "            index_cat = np.where(cat == self.categories)\n",
        "            self.Y_one_hot[index][index_cat] = 1\n",
        "        return self.Y_one_hot"
      ],
      "metadata": {
        "id": "UJwvJAwx-SUn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Image_Extraction_from_file:\n",
        "    def __init__(self,path_folder):\n",
        "        self.path_folder = path_folder\n",
        "        self.image_data = np.empty((28*28))\n",
        "\n",
        "    def Get_images(self,image_path):\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        image_array = np.array(image.getdata(),dtype=np.int32)/256\n",
        "        #append the image data into image data array which will contain all the image data with the category lable\n",
        "        self.image_data.append(image_array)\n",
        "\n",
        "    def Extract_from_folder(self):\n",
        "        category_name = []\n",
        "        self.image_data = []\n",
        "        for root, dirs, files in os.walk(self.path_folder):\n",
        "            for name in files:\n",
        "                if name.endswith(\".png\"):\n",
        "                    image_path = os.path.join(root, name)\n",
        "                    self.Get_images(image_path)\n",
        "                    subdir_name = os.path.basename(root)\n",
        "                    category_name.append(subdir_name)\n",
        "\n",
        "        self.image_data = np.array(self.image_data)\n",
        "        category_name = np.array(category_name).reshape(-1, 1)\n",
        "        unique_cat_list = np.unique(category_name)\n",
        "        # Combine image data with labels\n",
        "        self.image_data = np.hstack((self.image_data, category_name))\n",
        "        encode_one_hot = One_hot_encodeing(self.image_data,unique_cat_list)\n",
        "        self.Y_one_hot = encode_one_hot.encode()\n",
        "        return self.image_data[:,:-1].astype(float),self.Y_one_hot"
      ],
      "metadata": {
        "id": "tTYfgYv2-U-3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"C:\\\\CSE\\\\Chirag-Rao-KV\\\\Task 4.0\\\\Train\"\n",
        "Test_file = Image_Extraction_from_file(path)"
      ],
      "metadata": {
        "id": "OGY0Xtj9-XZr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kWDaZ6vZAARq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_images,Y_images = Test_file.Extract_from_folder()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "NUfoKWj5-ZIy",
        "outputId": "5845057c-9691-4967-936d-0d1b5ee7b9c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d493f9304a5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtract_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-aad2c599acd4>\u001b[0m in \u001b[0;36mExtract_from_folder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0munique_cat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Combine image data with labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mencode_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOne_hot_encodeing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_cat_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_one_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Layer_info = np.array([784,10,10,5,5])"
      ],
      "metadata": {
        "id": "7bGcpEDg-bMs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Layer_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIjo9x73-8A6",
        "outputId": "fc1e744e-fdb6-4b9c-b950-0a8c0c46baa9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([784,  10,  10,   5,   5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Neural_network = Train_Test_Neural_network(Layer_info,X_images,Y_images,X_images,Y_images)\n",
        "Neural_network.Train_layers(1,0.001)"
      ],
      "metadata": {
        "id": "oeLPf3K8-dJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfR-7-30-64G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}